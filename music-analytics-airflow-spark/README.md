## ğŸµ Pipeline d'Analyse Musicale avec Apache Spark & Airflow
## ğŸš€ Projet d'IngÃ©nierie des DonnÃ©es - Formation IBM
https://img.shields.io/badge/Apache%2520Airflow-2.7.1-green
https://img.shields.io/badge/Apache%2520Spark-3.5.0-red
https://img.shields.io/badge/Python-3.9-blue
https://img.shields.io/badge/Statut-Pr%C3%AAt%2520pour%2520Production-success

## ğŸ“‹ AperÃ§u du Projet
Pipeline de donnÃ©es complet pour l'analyse de streaming musical, dÃ©veloppÃ© pendant la formation Data Engineering d'IBM. Ce projet dÃ©montre des compÃ©tences rÃ©elles en ingÃ©nierie des donnÃ©es avec des technologies modernes de Big Data.

## âœ… Ce que j'ai construit
Traitement PySpark rÃ©el : Pas simulÃ© - vrai calcul distribuÃ© avec Apache Spark

DAG Airflow automatisÃ© : ExÃ©cution quotidienne avec monitoring et gestion d'erreurs

GÃ©nÃ©ration de donnÃ©es : DonnÃ©es de streaming musical rÃ©alistes avec patterns

Analyses complÃ¨tes : Classement des artistes, insights gÃ©ographiques, mÃ©triques d'utilisation

FonctionnalitÃ©s production : Logique de retry, validation des donnÃ©es, reporting automatisÃ©

## ğŸ—ï¸ Architecture
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Apache Airflow (DAG)            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚Startâ”‚â†’ â”‚GÃ©nÃ¨re   â”‚â†’ â”‚ Spark   â”‚     â”‚
â”‚  â”‚     â”‚  â”‚ DonnÃ©es â”‚  â”‚ Traite  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â”‚         â”‚         â”‚           â”‚
â”‚         â–¼         â–¼         â–¼           â”‚
â”‚  [Rapports]  [Fichiers]  [DonnÃ©es]     â”‚
â”‚              [CSV]        [JSON]        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
## ğŸ“Š Ã‰tapes du Pipeline
GÃ©nÃ©ration de donnÃ©es : CrÃ©ation de donnÃ©es de streaming synthÃ©tiques (500+ enregistrements)

Traitement Spark : Analyses distribuÃ©es avec agrÃ©gations PySpark

Analyse : Calcul du classement des artistes, statistiques par pays, utilisation des appareils

Reporting : GÃ©nÃ©ration de rÃ©sumÃ©s JSON et rapports Markdown

Nettoyage : Gestion automatique des fichiers temporaires

## ğŸ› ï¸ Technologies UtilisÃ©es
Technologie	Objectif	Version
Apache Airflow	Orchestration de workflows	2.7.1
Apache Spark	Traitement distribuÃ© de donnÃ©es	3.5.0
PySpark	Interface Python pour Spark	3.5.0
Pandas	Manipulation et gÃ©nÃ©ration de donnÃ©es	2.0.3
NumPy	Calculs numÃ©riques	1.24.3
## ğŸ“ Structure du Projet
music-analytics-airflow-spark/
â”œâ”€â”€ music_analytics_dag.py     # DAG Airflow complet
â”œâ”€â”€ README.md                  # Cette documentation
â”œâ”€â”€ requirements.txt           # DÃ©pendances Python
â”œâ”€â”€ .gitignore                # RÃ¨gles Git ignore
â””â”€â”€ sample_output/            # Exemples de fichiers gÃ©nÃ©rÃ©s
## ğŸš€ DÃ©marrage Rapide
PrÃ©requis
Python 3.9+

Java 8+ (pour Spark)

Apache Airflow 2.7+

## Installation
# 1. Cloner le repository
git clone https://github.com/votrenom/music-analytics-airflow-spark.git
cd music-analytics-airflow-spark

# 2. Installer les dÃ©pendances
pip install -r requirements.txt

# 3. Initialiser Airflow
export AIRFLOW_HOME=$(pwd)/airflow
airflow db init
airflow users create \
    --username admin \
    --firstname Admin \
    --lastname User \
    --role Admin \
    --email admin@example.com \
    --password admin

# 4. Copier le DAG dans Airflow
mkdir -p $AIRFLOW_HOME/dags
cp music_analytics_dag.py $AIRFLOW_HOME/dags/
# ExÃ©cution du Pipeline

# DÃ©marrer les services Airflow
airflow webserver --port 8080 --daemon
airflow scheduler --daemon

# DÃ©clencher le DAG
airflow dags trigger music_analytics_with_spark

# Monitorer l'exÃ©cution (ouvrir dans le navigateur)
# http://localhost:8080

## ğŸ¯ FonctionnalitÃ©s ClÃ©s ImplÃ©mentÃ©es
## 1. Traitement Spark RÃ©el
PySpark 3.5.0 rÃ©el (pas simulÃ© ou mockÃ©)

Calculs distribuÃ©s sur machine locale

Configuration et gestion appropriÃ©e de SparkSession

Utilisation mÃ©moire efficace (2GB allouÃ©s)

## 2. DAG Airflow de QualitÃ© Production
ExÃ©cution planifiÃ©e quotidienne (@daily)

Retry automatique en cas d'Ã©chec (2 tentatives)

Logging et monitoring complets

Notifications email en cas d'Ã©chec (configurable)

## 3. QualitÃ© & Validation des DonnÃ©es
Validation du schÃ©ma des donnÃ©es gÃ©nÃ©rÃ©es

VÃ©rification des plages (plays positifs, durÃ©es valides)

VÃ©rification de la complÃ©tude des donnÃ©es

Nettoyage automatique des anciens fichiers

## 4. Analytics Business-Ready
Classement de popularitÃ© des artistes

Analyse de distribution gÃ©ographique

Patterns d'utilisation des appareils

Analyse des tendances temporelles

Export vers multiples formats (CSV, JSON, Markdown)